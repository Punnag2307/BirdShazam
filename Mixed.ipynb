{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7272bcb-957d-40f8-8d13-537ea5194919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Mixed training CSV created with 20000 samples:\n",
      "   🐦  Single-label: 14000\n",
      "   🐦  Multi-label : 6000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# ✅ Paths to your original CSVs\n",
    "single_csv_path = \"clean_singlelabel_train.csv\"         # 295k+ samples\n",
    "multi_csv_path  = \"mixed_multilabel_train.csv\"          # 15k mixed samples\n",
    "\n",
    "# ✅ Parameters\n",
    "num_single_label = 14000\n",
    "num_multi_label = 6000\n",
    "random_seed = 42\n",
    "\n",
    "# ✅ Load both CSVs\n",
    "df_single = pd.read_csv(single_csv_path)\n",
    "df_multi = pd.read_csv(multi_csv_path)\n",
    "\n",
    "# ✅ Rename single-label column to 'labels'\n",
    "if 'label' in df_single.columns:\n",
    "    df_single['labels'] = df_single['label']\n",
    "    df_single.drop(columns=['label'], inplace=True)\n",
    "\n",
    "# ✅ Randomly sample\n",
    "df_single_sampled = df_single.sample(n=num_single_label, random_state=random_seed).reset_index(drop=True)\n",
    "df_multi_sampled = df_multi.sample(n=num_multi_label, random_state=random_seed).reset_index(drop=True)\n",
    "\n",
    "# ✅ Combine\n",
    "df_mixed = pd.concat([df_single_sampled, df_multi_sampled], ignore_index=True)\n",
    "df_mixed = df_mixed.sample(frac=1, random_state=random_seed).reset_index(drop=True)  # shuffle\n",
    "\n",
    "# ✅ Save\n",
    "df_mixed.to_csv(\"train_split_mixed.csv\", index=False)\n",
    "print(f\"✅ Mixed training CSV created with {len(df_mixed)} samples:\")\n",
    "print(f\"   🐦  Single-label: {num_single_label}\")\n",
    "print(f\"   🐦  Multi-label : {num_multi_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c51ec608-2495-4e45-9d10-a53132392e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Copying 20000 spectrograms to E:/birdclef-2024/train_mixed_spects...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔄 Copying files: 100%|██████████| 20000/20000 [02:32<00:00, 131.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All spectrograms copied successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ✅ CSV with relative filepaths\n",
    "csv_path = \"train_split_mixed.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# ✅ Source roots\n",
    "single_root = \"E:/birdclef-2024/spectrograms\"\n",
    "multi_root  = \"E:/birdclef-2024/mixed_multilabel_spects\"\n",
    "\n",
    "# ✅ Destination root\n",
    "target_dir = \"E:/birdclef-2024/train_mixed_spects\"\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "# ✅ Start copy\n",
    "print(f\"📦 Copying {len(df)} spectrograms to {target_dir}...\\n\")\n",
    "\n",
    "for filepath in tqdm(df[\"filepath\"], desc=\"🔄 Copying files\"):\n",
    "    fname = os.path.basename(filepath)\n",
    "\n",
    "    # Detect source\n",
    "    if \"mixed_multilabel_spects\" in filepath or fname.startswith(\"mix_\"):\n",
    "        src = os.path.join(multi_root, fname)\n",
    "    else:\n",
    "        # species subfolder in original\n",
    "        species = os.path.basename(os.path.dirname(filepath))\n",
    "        src = os.path.join(single_root, species, fname)\n",
    "\n",
    "    dst = os.path.join(target_dir, fname)\n",
    "    shutil.copy(src, dst)\n",
    "\n",
    "print(\"✅ All spectrograms copied successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a5fddd4-5e02-4cb7-9357-7cadef3ea2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Updated CSV saved as train_split_mixed_updated.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "csv_path = \"train_split_mixed.csv\"\n",
    "output_path = \"train_split_mixed_updated.csv\"\n",
    "target_dir = \"E:/birdclef-2024/train_mixed_spects\"\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Replace with new path\n",
    "df[\"filepath\"] = df[\"filepath\"].apply(lambda x: os.path.join(target_dir, os.path.basename(x)))\n",
    "\n",
    "# Save updated CSV\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"✅ Updated CSV saved as {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c10e1afc-a7f6-46a0-94b5-cec48103e338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import os\n",
    "\n",
    "class BirdMultiLabelDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_size=(300, 300), transform=None):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.image_size = image_size\n",
    "        self.transform = transform\n",
    "\n",
    "        self.df['labels'] = self.df['labels'].apply(lambda x: x.split(\"|\"))\n",
    "        self.mlb = MultiLabelBinarizer()\n",
    "        self.label_matrix = self.mlb.fit_transform(self.df['labels'])\n",
    "        self.label_names = self.mlb.classes_\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image = Image.open(row['filepath']).convert(\"RGB\").resize(self.image_size)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            image = torch.tensor(np.array(image) / 255.0).permute(2, 0, 1).float()\n",
    "\n",
    "        label = torch.tensor(self.label_matrix[idx]).float()\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22e3f435-ea66-4125-a2f2-2c2d19869ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "image_transforms = transforms.Compose([\n",
    "    transforms.Resize((300, 300)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "])\n",
    "\n",
    "dataset = BirdMultiLabelDataset(\"train_split_mixed_updated.csv\", transform=image_transforms)\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30f9ec45-7e32-40d2-b634-3911f6ca3406",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BirdMultiLabelDataset(\"train_split_mixed_train.csv\", transform=image_transforms)\n",
    "val_dataset = BirdMultiLabelDataset(\"train_split_mixed_val.csv\", transform=image_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0a1ce209-3016-4ed5-9e26-e3057249dd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"train_split_mixed_updated.csv\")\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_df.to_csv(\"train_split_mixed_train.csv\", index=False)\n",
    "val_df.to_csv(\"train_split_mixed_val.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "36153985-3568-42f6-86bb-2fe272a6a8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = timm.create_model(\"efficientnet_b3\", pretrained=True, num_classes=181)\n",
    "model.to(device)\n",
    "\n",
    "# Binary label matrix from your dataset\n",
    "label_counts = dataset.label_matrix.sum(axis=0)  # shape (181,)\n",
    "total_samples = len(dataset)\n",
    "\n",
    "# Inverse frequency → rarer classes get higher weights\n",
    "pos_weights = torch.tensor((total_samples - label_counts) / (label_counts + 1e-6), dtype=torch.float32).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "71e9e8c9-6019-4b19-b924-1654b06ddb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_label_smoothing(labels, smoothing=0.05):\n",
    "    return labels * (1 - smoothing) + 0.5 * smoothing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9be73129-bbb2-4a1a-825b-d610150ae149",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def evaluate_model(model, val_loader, device, threshold=0.5):\n",
    "    model.eval()\n",
    "    preds, true = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            output = torch.sigmoid(model(x)).cpu().numpy()\n",
    "            preds.append(output)\n",
    "            true.append(y.cpu().numpy())\n",
    "\n",
    "    preds = np.vstack(preds)\n",
    "    true = np.vstack(true)\n",
    "\n",
    "    preds_bin = (preds > threshold).astype(int)\n",
    "    val_f1 = f1_score(true, preds_bin, average='macro')\n",
    "\n",
    "    return val_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66829df-3128-41a1-8353-f058e9abe2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/6: 100%|██████████| 500/500 [43:58<00:00,  5.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📘 Epoch 1 Training Loss: 2.5783\n",
      "✅ Epoch 1 Val Macro F1: 0.0182\n",
      "💾 Saved model with F1: 0.0182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/6: 100%|██████████| 500/500 [42:53<00:00,  5.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📘 Epoch 2 Training Loss: 2.4793\n",
      "✅ Epoch 2 Val Macro F1: 0.0195\n",
      "💾 Saved model with F1: 0.0195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/6:  75%|███████▌  | 376/500 [30:43<10:28,  5.07s/it]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "best_val_f1 = 0.0\n",
    "\n",
    "for epoch in range(6):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{6}\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        smoothed = apply_label_smoothing(labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, smoothed)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f\"📘 Epoch {epoch+1} Training Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # ✅ Optional: Validation step if you have val_loader\n",
    "    model.eval()\n",
    "    preds, true = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            output = torch.sigmoid(model(x)).cpu().numpy()\n",
    "            preds.append(output)\n",
    "            true.append(y.cpu().numpy())\n",
    "\n",
    "    preds = np.vstack(preds)\n",
    "    true = np.vstack(true)\n",
    "\n",
    "    # Convert to binary (threshold at 0.5)\n",
    "    preds_bin = (preds > 0.5).astype(int)\n",
    "\n",
    "    # Macro F1-score\n",
    "    val_f1 = f1_score(true, preds_bin, average='macro')\n",
    "    print(f\"✅ Epoch {epoch+1} Val Macro F1: {val_f1:.4f}\")\n",
    "\n",
    "    # ✅ Save best model\n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        torch.save(model.state_dict(), \"best_multilabel_model.pth\")\n",
    "        print(f\"💾 Saved model with F1: {val_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e5225d-e6fb-48ed-96b3-e91144cf3af2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
