{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3646e165-75c2-4657-aff3-6accfa56cd94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8444/8444 [58:12<00:00,  2.42it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Filtered soundscape segmentation completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ✅ Set paths\n",
    "soundscape_dir = \"E:/birdclef-2024/unlabeled_soundscapes\"\n",
    "output_dir = \"E:/birdclef-2024/unlabeled_segments_filtered\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# ✅ Parameters\n",
    "sample_rate = 32000\n",
    "segment_duration = 5  # seconds\n",
    "samples_per_segment = sample_rate * segment_duration\n",
    "max_segments_per_file = 10\n",
    "\n",
    "# ✅ Process each soundscape file\n",
    "for filename in tqdm(os.listdir(soundscape_dir)):\n",
    "    if not filename.endswith(\".ogg\") and not filename.endswith(\".wav\"):\n",
    "        continue\n",
    "\n",
    "    file_path = os.path.join(soundscape_dir, filename)\n",
    "    y, sr = librosa.load(file_path, sr=sample_rate)\n",
    "    soundscape_id = os.path.splitext(filename)[0]\n",
    "\n",
    "    # Detect non-silent intervals (in samples)\n",
    "    intervals = librosa.effects.split(y, top_db=30)  # adjust top_db to tune sensitivity\n",
    "\n",
    "    segment_count = 0\n",
    "    for start_sample, end_sample in intervals:\n",
    "        if segment_count >= max_segments_per_file:\n",
    "            break\n",
    "\n",
    "        segment = y[start_sample:end_sample]\n",
    "\n",
    "        # Skip if the active segment is shorter than 5 seconds\n",
    "        if len(segment) < samples_per_segment:\n",
    "            continue\n",
    "\n",
    "        # Chop into consecutive 5s chunks from this active region\n",
    "        for i in range(0, len(segment) - samples_per_segment + 1, samples_per_segment):\n",
    "            if segment_count >= max_segments_per_file:\n",
    "                break\n",
    "\n",
    "            chunk = segment[i:i + samples_per_segment]\n",
    "            segment_filename = f\"{soundscape_id}_{segment_count*5}_{(segment_count+1)*5}.wav\"\n",
    "            segment_path = os.path.join(output_dir, segment_filename)\n",
    "            sf.write(segment_path, chunk, samplerate=sample_rate)\n",
    "            segment_count += 1\n",
    "\n",
    "print(\"✅ Filtered soundscape segmentation completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c1707ec-84a7-4bf1-9c61-d71d06d28514",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 1:   0%|          | 0/1000 [00:00<?, ?it/s]C:\\Users\\ONGC\\AppData\\Local\\Temp\\ipykernel_40168\\35302409.py:40: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  colormap = cm.get_cmap('viridis')\n",
      "Processing batch 1: 100%|██████████| 1000/1000 [03:51<00:00,  4.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 2: 100%|██████████| 1000/1000 [03:49<00:00,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 3: 100%|██████████| 1000/1000 [03:40<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 4: 100%|██████████| 1000/1000 [03:37<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 5: 100%|██████████| 1000/1000 [03:42<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 6: 100%|██████████| 1000/1000 [03:41<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 7: 100%|██████████| 1000/1000 [04:10<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 8: 100%|██████████| 1000/1000 [04:28<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 9: 100%|██████████| 1000/1000 [04:23<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 10: 100%|██████████| 1000/1000 [04:20<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 11: 100%|██████████| 1000/1000 [04:19<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 12: 100%|██████████| 1000/1000 [04:16<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 13: 100%|██████████| 1000/1000 [04:15<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 14: 100%|██████████| 1000/1000 [04:02<00:00,  4.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 15: 100%|██████████| 1000/1000 [04:03<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 16: 100%|██████████| 1000/1000 [04:01<00:00,  4.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 17: 100%|██████████| 1000/1000 [04:01<00:00,  4.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 18: 100%|██████████| 1000/1000 [03:53<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 19: 100%|██████████| 1000/1000 [03:56<00:00,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 20: 100%|██████████| 1000/1000 [03:55<00:00,  4.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 21: 100%|██████████| 1000/1000 [03:56<00:00,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 22: 100%|██████████| 1000/1000 [03:57<00:00,  4.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 23: 100%|██████████| 1000/1000 [03:58<00:00,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 24: 100%|██████████| 1000/1000 [03:54<00:00,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 25: 100%|██████████| 1000/1000 [03:53<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 26: 100%|██████████| 1000/1000 [03:53<00:00,  4.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 27: 100%|██████████| 1000/1000 [04:04<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 28: 100%|██████████| 1000/1000 [04:30<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 29: 100%|██████████| 1000/1000 [04:10<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 30: 100%|██████████| 1000/1000 [04:02<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 31: 100%|██████████| 1000/1000 [03:54<00:00,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 32: 100%|██████████| 1000/1000 [03:54<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 33: 100%|██████████| 1000/1000 [03:57<00:00,  4.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 34: 100%|██████████| 1000/1000 [05:20<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 35: 100%|██████████| 1000/1000 [03:48<00:00,  4.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 36: 100%|██████████| 1000/1000 [03:57<00:00,  4.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 37: 100%|██████████| 1000/1000 [03:46<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 38: 100%|██████████| 1000/1000 [03:44<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 39: 100%|██████████| 1000/1000 [03:55<00:00,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 40: 100%|██████████| 1000/1000 [03:55<00:00,  4.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 41: 100%|██████████| 1000/1000 [03:47<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 42: 100%|██████████| 1000/1000 [03:50<00:00,  4.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 43: 100%|██████████| 1000/1000 [03:51<00:00,  4.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 44: 100%|██████████| 1000/1000 [03:50<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 45: 100%|██████████| 1000/1000 [03:47<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 46: 100%|██████████| 1000/1000 [03:49<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 47: 100%|██████████| 1000/1000 [03:51<00:00,  4.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 48: 100%|██████████| 1000/1000 [03:46<00:00,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 49: 100%|██████████| 1000/1000 [03:48<00:00,  4.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 50: 100%|██████████| 1000/1000 [03:46<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 51: 100%|██████████| 1000/1000 [03:48<00:00,  4.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 52: 100%|██████████| 1000/1000 [03:48<00:00,  4.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 53: 100%|██████████| 1000/1000 [03:48<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 54: 100%|██████████| 1000/1000 [04:03<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 55: 100%|██████████| 1000/1000 [03:57<00:00,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 56: 100%|██████████| 1000/1000 [03:57<00:00,  4.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 57: 100%|██████████| 1000/1000 [03:57<00:00,  4.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 58: 100%|██████████| 1000/1000 [03:55<00:00,  4.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 59: 100%|██████████| 1000/1000 [03:55<00:00,  4.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 60: 100%|██████████| 1000/1000 [03:50<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 61: 100%|██████████| 1000/1000 [03:46<00:00,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 62: 100%|██████████| 1000/1000 [03:54<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 63: 100%|██████████| 1000/1000 [03:56<00:00,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 64: 100%|██████████| 1000/1000 [03:52<00:00,  4.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 65: 100%|██████████| 1000/1000 [03:50<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 66: 100%|██████████| 1000/1000 [03:49<00:00,  4.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 67: 100%|██████████| 1000/1000 [03:50<00:00,  4.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 68: 100%|██████████| 1000/1000 [03:51<00:00,  4.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 69: 100%|██████████| 1000/1000 [03:47<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 70: 100%|██████████| 1000/1000 [03:42<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 71: 100%|██████████| 1000/1000 [03:41<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 72: 100%|██████████| 1000/1000 [03:54<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 73: 100%|██████████| 1000/1000 [03:50<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 74: 100%|██████████| 1000/1000 [04:08<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 75: 100%|██████████| 1000/1000 [03:50<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 76: 100%|██████████| 1000/1000 [03:47<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 77: 100%|██████████| 1000/1000 [03:43<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 78: 100%|██████████| 1000/1000 [03:45<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 79: 100%|██████████| 1000/1000 [03:46<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 80: 100%|██████████| 1000/1000 [03:48<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 81: 100%|██████████| 1000/1000 [03:46<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 82: 100%|██████████| 279/279 [01:04<00:00,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed batch 82\n",
      "✅ Mel spectrogram generation completed in color with colormap.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "# ✅ Paths\n",
    "input_dir = \"E:/birdclef-2024/unlabeled_segments_filtered\"\n",
    "output_dir = \"E:/birdclef-2024/unlabeled_mels\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# ✅ Parameters\n",
    "sample_rate = 32000\n",
    "n_mels = 128\n",
    "n_fft = 1042\n",
    "hop_length = 500\n",
    "batch_size = 1000\n",
    "\n",
    "# ✅ Get list of .wav files\n",
    "all_files = [f for f in os.listdir(input_dir) if f.endswith(\".wav\")]\n",
    "\n",
    "for batch_start in range(0, len(all_files), batch_size):\n",
    "    batch_files = all_files[batch_start:batch_start + batch_size]\n",
    "\n",
    "    for filename in tqdm(batch_files, desc=f\"Processing batch {batch_start // batch_size + 1}\"):\n",
    "        file_path = os.path.join(input_dir, filename)\n",
    "        y, sr = librosa.load(file_path, sr=sample_rate)\n",
    "\n",
    "        # Generate mel spectrogram in dB\n",
    "        S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels, n_fft=n_fft, hop_length=hop_length)\n",
    "        S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "        # Normalize and convert to colormap (like matplotlib's 'viridis')\n",
    "        S_dB_norm = 255 * (S_dB - S_dB.min()) / (S_dB.max() - S_dB.min())\n",
    "        S_img = S_dB_norm.astype(np.uint8)\n",
    "\n",
    "        colormap = cm.get_cmap('viridis')\n",
    "        S_colored = colormap(S_img / 255.0)[:, :, :3]  # Drop alpha channel\n",
    "        S_rgb = (S_colored * 255).astype(np.uint8)\n",
    "\n",
    "        # Resize to 224x224\n",
    "        S_img_resized = cv2.resize(S_rgb, (224, 224), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # Save as PNG image\n",
    "        output_path = os.path.join(output_dir, filename.replace(\".wav\", \".png\"))\n",
    "        cv2.imwrite(output_path, cv2.cvtColor(S_img_resized, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        gc.collect()\n",
    "\n",
    "    print(f\"✅ Completed batch {batch_start // batch_size + 1}\")\n",
    "\n",
    "print(\"✅ Mel spectrogram generation completed in color with colormap.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64a4f167-9cd3-4f64-a519-d5ccc59140cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ONGC\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ONGC\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "100%|██████████| 81279/81279 [00:00<00:00, 2881828.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Inference completed and predictions saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#INFERENCE MODEL ON UNLABELED SOUNDSCAPE USING RESNET-50\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# ✅ Paths\n",
    "model_path = \"best_resnet50_model.pth\"\n",
    "mels_dir = \"E:/birdclef-2024/unlabeled_mels\"\n",
    "output_csv = \"E:/birdclef-2024/unlabeled_predictions.csv\"\n",
    "\n",
    "# ✅ Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ✅ Load model\n",
    "model = models.resnet50(pretrained=False)\n",
    "model.fc = nn.Linear(model.fc.in_features, 181)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# ✅ Transforms\n",
    "inference_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "])\n",
    "\n",
    "# ✅ Check existing predictions to resume\n",
    "existing_files = set()\n",
    "if os.path.exists(output_csv):\n",
    "    existing_df = pd.read_csv(output_csv)\n",
    "    existing_files = set(existing_df['filename'].tolist())\n",
    "    results = existing_df.values.tolist()\n",
    "else:\n",
    "    results = []\n",
    "\n",
    "# ✅ Inference\n",
    "image_files = sorted([f for f in os.listdir(mels_dir) if f.endswith(\".png\")])\n",
    "batch_size = 1000  # Save progress every 1000 files\n",
    "buffer = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, img_file in enumerate(tqdm(image_files)):\n",
    "        if img_file in existing_files:\n",
    "            continue\n",
    "\n",
    "        img_path = os.path.join(mels_dir, img_file)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        tensor = inference_transforms(image).unsqueeze(0).to(device)\n",
    "\n",
    "        outputs = model(tensor)\n",
    "        probs = torch.softmax(outputs, dim=1).squeeze().cpu().numpy()\n",
    "\n",
    "        buffer.append([img_file] + list(probs))\n",
    "\n",
    "        # Save every `batch_size` predictions\n",
    "        if len(buffer) >= batch_size:\n",
    "            results.extend(buffer)\n",
    "            df = pd.DataFrame(results, columns=[\"filename\"] + [f\"class_{i}\" for i in range(181)])\n",
    "            df.to_csv(output_csv, index=False)\n",
    "            buffer = []  # Clear buffer\n",
    "\n",
    "# ✅ Final save\n",
    "if buffer:\n",
    "    results.extend(buffer)\n",
    "    df = pd.DataFrame(results, columns=[\"filename\"] + [f\"class_{i}\" for i in range(181)])\n",
    "    df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(\"✅ Inference completed and predictions saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ec617aa-d4b4-4647-acad-b9ffdbf40efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81279/81279 [1:39:04<00:00, 13.67it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Inference completed and predictions saved.\n"
     ]
    }
   ],
   "source": [
    "#INFERENCE MODEL ON UNLABELED SOUNDSCAPE USING EFFICIENT NET-B3\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import timm\n",
    "from torchvision import transforms\n",
    "\n",
    "# ✅ Paths\n",
    "model_path = \"best_efficientnet_b3_model.pth\"\n",
    "mels_dir = \"E:/birdclef-2024/unlabeled_mels\"\n",
    "output_csv = \"E:/birdclef-2024/unlabeled_predictions_b3.csv\"\n",
    "\n",
    "# ✅ Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ✅ Load EfficientNet-B3 model\n",
    "model = timm.create_model(\"efficientnet_b3\", pretrained=False, num_classes=181)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# ✅ Transforms (300x300 for EfficientNet-B3)\n",
    "inference_transforms = transforms.Compose([\n",
    "    transforms.Resize((300, 300)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "])\n",
    "\n",
    "# ✅ Check existing predictions to resume\n",
    "existing_files = set()\n",
    "if os.path.exists(output_csv):\n",
    "    existing_df = pd.read_csv(output_csv)\n",
    "    existing_files = set(existing_df['filename'].tolist())\n",
    "    results = existing_df.values.tolist()\n",
    "else:\n",
    "    results = []\n",
    "\n",
    "# ✅ Inference loop\n",
    "image_files = sorted([f for f in os.listdir(mels_dir) if f.endswith(\".png\")])\n",
    "batch_size = 1000\n",
    "buffer = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, img_file in enumerate(tqdm(image_files)):\n",
    "        if img_file in existing_files:\n",
    "            continue\n",
    "\n",
    "        img_path = os.path.join(mels_dir, img_file)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        tensor = inference_transforms(image).unsqueeze(0).to(device)\n",
    "\n",
    "        outputs = model(tensor)\n",
    "        probs = torch.softmax(outputs, dim=1).squeeze().cpu().numpy()\n",
    "\n",
    "        buffer.append([img_file] + list(probs))\n",
    "\n",
    "        if len(buffer) >= batch_size:\n",
    "            results.extend(buffer)\n",
    "            df = pd.DataFrame(results, columns=[\"filename\"] + [f\"class_{i}\" for i in range(181)])\n",
    "            df.to_csv(output_csv, index=False)\n",
    "            buffer = []\n",
    "\n",
    "# ✅ Final save\n",
    "if buffer:\n",
    "    results.extend(buffer)\n",
    "    df = pd.DataFrame(results, columns=[\"filename\"] + [f\"class_{i}\" for i in range(181)])\n",
    "    df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(\"✅ Inference completed and predictions saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d2090c-05d2-4e18-ae35-95511f5655eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
